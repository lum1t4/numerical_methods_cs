\chapter[short]{Eigenvalues and Eigenvectors}
Given a matrix \( A \) of size \( n \times n \) and a scalar \( \lambda \) and a vector \( \mathbf{x} \neq \mathbf{0} \) such that
\[
A\mathbf{x} = \lambda \mathbf{x},
\]
then \( \lambda \) is said to be an eigenvalue of \( A \), and \( \mathbf{x} \) is said to be an eigenvector of \( A \).

To compute \( \lambda \), we can proceed as follows:
\begin{align*}
A\mathbf{x} &= \lambda \mathbf{x} \\
A\mathbf{x} - \lambda \mathbf{x} &= \mathbf{0} \\
(A - \lambda I)\mathbf{x} &= \mathbf{0}
\end{align*}

Here we have a homogeneous linear system. From the theory, we know that if the matrix has maximum rank,
then there is only a unique solution which is the trivial solution. But given the definition above, in this
case \( \mathbf{x} \neq \mathbf{0} \), this implies that necessarily the matrix \( A - \lambda I \) must be
singular so the determinant of \( A - \lambda I \) must equals to zero
\[
\det(A - \lambda I) = 0
\]
The determinant \( \det(A - \lambda I) \) is a polynomial in the unknown \( \lambda \),
which is called the characteristic polynomial. The roots of this polynomial will be the
eigenvalues of \( A \).

All the eigenvalues of \( A \) form the spectrum of \( A \), denoted as 
\[
\sigma(A) = \{ \lambda_1, \lambda_2, \ldots, \lambda_n \}.
\]

The pair \( (\lambda, \mathbf{x}) \) is called an eigenpair of \( A \).

If \( \mathbf{x} \) is an eigenvector of \( A \), then by definition
\[
(A - \lambda I)\mathbf{x} = \mathbf{0} \quad \Rightarrow \quad \mathbf{x} \in \underbrace{\mathcal{N}(A - \lambda I)}_{\text{Eigenspace}},
\]

\textbf{Example.} Compute the eigenvalues and eigenvectors of the matrix $A$
\[
A = \begin{pmatrix}
4 & -5 \\
2 & -3
\end{pmatrix}.
\]
1. Write \((A - \lambda I)\) and set the determinant to zero to find the characteristic polynomial.

$$ A - \lambda I = \begin{pmatrix}
4 & -5 \\
2 & -3
\end{pmatrix} - \begin{pmatrix}
\lambda & 0 \\
0 & \lambda
\end{pmatrix} = \begin{pmatrix}
4 - \lambda & -5 \\
2 & -3 - \lambda
\end{pmatrix} $$


\begin{align*}
    \det \begin{pmatrix}
        4 - \lambda & -5 \\
        2 & -3 - \lambda
        \end{pmatrix} &= (4-\lambda)(-3-\lambda) - (-10) \\
        &= -12 - 4\lambda + 3\lambda + \lambda^2 + 10 \\
        &= \lambda^2 - \lambda - 2 = 0
\end{align*}
\[
\lambda = \frac{-(-1) \pm \sqrt{(-1)^2 - 4(1)(-2)}}{2(1)} = \frac{1 \pm \sqrt{9}}{2} = \frac{1 \pm 3}{2}
\]
Thus, we get \(\lambda_1 = 2\) and \(\lambda_2 = -1\).

2. Computation of eigenvectors: \newline

For \((A - \lambda I)X = 0\), solve the system:
\[ (A - \lambda_1 I)X = \left[\begin{pmatrix} 4 & -5 \\ 2 & -3 \end{pmatrix} - \begin{pmatrix} 2 & 0 \\ 0 & 2 \end{pmatrix}\right] X = \mathbf{0} \]
This simplifies to:
\[
\begin{pmatrix}
2 & -5 \\
2 & -5
\end{pmatrix} \begin{pmatrix}
x_1 \\
x_2
\end{pmatrix} = \mathbf{0}
\]
For \(\lambda_1 = 2\), we get \(2x_1 - 5x_2 = 0\). Solving for \(x_1\), we have \(x_1 = \frac{5}{2} x_2\).

The general solution is:
\[
\begin{pmatrix}
x_1 \\
x_2
\end{pmatrix} = x_2 \begin{pmatrix}
5/2 \\
1
\end{pmatrix}
\]
Thus, \(X_1 = \begin{pmatrix}
5/2 \\
1
\end{pmatrix}\) is an eigenvector.

Repeat the process for \(\lambda_2\) to find the second eigenvector.
\subsection{Complex Eigenvalues for Real Matrices}

\begin{itemize}
    \item A matrix \( A \) with real entries can have complex eigenvalues.
    \item If a matrix \( A \) with real entries has an eigenvalue \( \lambda \in \mathbb{C}\),
    then also the conjugate \(\bar{\lambda}\) is an eigenvalue of \( A \).
\end{itemize}
If \( \lambda \in \mathbb{C} \) is an eigenvalue then $ A\mathbf{x} = \lambda\mathbf{x} \quad \mathbf{x} \neq 0$. If we consider its complex conjugate, we get:
\begin{align*}
    \overline{A\mathbf{x}} = \overline{A}\overline{\mathbf{x}} &= A\overline{\mathbf{x}} \\
    A\mathbf{x} &= \lambda\mathbf{x} \Rightarrow\overline{(A\mathbf{x})} = \overline{\lambda\mathbf{x}} \\
    &\Rightarrow A\bar{\mathbf{x}} = \bar{\lambda}\bar{\mathbf{x}} \quad \Rightarrow \quad \bar{\lambda} \text{ is also an eigenvalue of } A
\end{align*}

\subsection{Eigenvalues of \( 2 \times 2 \) Matrices}
For \( 2 \times 2 \) matrices the following holds:
\begin{align*}
    A = \begin{pmatrix} a & b \\ c & d \end{pmatrix}
    \quad
    \begin{aligned}
        trace(A) &= a + d \\
        det(A) &= ad - bc\
    \end{aligned}
\end{align*}
To compute \( \lambda \) if we assume the characteristic equation:

\begin{align*}
    det(A - \lambda I) &= det \begin{pmatrix} a - \lambda & b \\ c & d - \lambda \end{pmatrix} \\
    &= (a - \lambda)(d - \lambda) - bc \\
    &= ad - a\lambda - \lambda d + \lambda^2 - bc \\
    &= \lambda^2 - \lambda(\underbrace{a + d}_{trace(A)}) + \underbrace{ad - bc}_{det(A)} \\
\end{align*}

$$ \lambda = \frac{trace(A) \pm \sqrt{trace(A)^2 - 4 \cdot det(A)}}{2} $$
In general, we have
\begin{align*}
    \sum_{i=1}^{n} \lambda_i &= trace(A) \\
    \prod_{i=1}^{n} \lambda_i &= det(A)
\end{align*}

\textbf{Theorem:}
If a matrix \( A \) is singular then it has at least one null eigenvalue.

\textbf{Proof:}
If the matrix \( A \) is singular its determinant is zero:
\[
    det(A) = 0 \Rightarrow \prod_{i=1}^{n} \lambda_i = 0 \Rightarrow \exists i: \lambda_i = 0.
\]

Given a matrix \( A \) of size \( m \times m \) which is diagonal:
\[
A = \begin{pmatrix}
d_{11} & 0 & \cdots & 0 \\
0 & d_{22} & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & d_{mm}
\end{pmatrix}
\]

What are its eigenvalues?

\begin{enumerate}
    \item We construct \( (A - \lambda I) \)
    \item Compute \( \text{det}(A - \lambda I) \):
    \[
        det \begin{pmatrix}
        d_{11} - \lambda & 0 & \cdots & 0 \\
        0 & d_{22} - \lambda & \cdots & 0 \\
        \vdots & \vdots & \ddots & \vdots \\
        0 & 0 & \cdots & d_{mm} - \lambda
        \end{pmatrix} = (d_{11} - \lambda)(d_{22} - \lambda) \cdots (d_{mm} - \lambda) = 0
    \]
    \[
        d_{11} = \lambda_1, \quad d_{22} = \lambda_2, \quad \ldots, \quad d_{mm} = \lambda_m
    \]
\end{enumerate}
Also for Triangular matrices: The eigenvalues of the elements on the main diagonal.

\begin{itemize}
\item The eigenvalues of \( A \) are the same as the eigenvalues of \( A^T \).
\item The eigenvalues of \( A^k \) are equal to the k-th power of the eigenvalues of \( A \).
    \begin{align*}
        A\mathbf{x} &= \lambda \mathbf{x} \\
        A^2\mathbf{x} &= A(A\mathbf{x}) = A(\lambda \mathbf{x}) = \lambda (A\mathbf{x}) = \lambda^2 \mathbf{x} \\
        A^3\mathbf{x} &= A(A^2\mathbf{x}) = A(\lambda^2 \mathbf{x}) = \lambda^2 (A\mathbf{x}) = \lambda^3 \mathbf{x} \\
        \vdots \\
        A^k\mathbf{x} &= \lambda^k \mathbf{x}
    \end{align*}
\item If a given matrix $A$ is not singular and $\lambda$ is an eigenvalue of $A$, then $\lambda^{-1}$ is an eigenvalue of the inverse matrix.
    \begin{align*}
        A\mathbf{x} &= \lambda \mathbf{x} , \quad A \text{ is not singular} \\
        A^{-1}A\mathbf{x} &= A^{-1} \lambda \mathbf{x} \\
        I\mathbf{x} &= \lambda A^{-1} \mathbf{x} \\
        \frac{1}{\lambda} \mathbf{x} &= A^{-1} \mathbf{x}
    \end{align*}
\item For a matrix \( A \) of size \( m \times m \), the number
    $\rho(A) := \max\{|\lambda_1|, |\lambda_2|, \ldots, |\lambda_m|\}$
    is called \textbf{spectral radius} of the matrix $A$.
    We can prove that $\rho(A) \leq ||A||$. \newline
    Let be $\lambda$ an eigenvalue of $A$ and $\mathbf{x}$ the corresponding eigenvector.
    \begin{align*}
        \left\{
        \begin{aligned}
            A\mathbf{x} &= \lambda \mathbf{x} \\
            ||A\mathbf{x}|| &= ||\lambda \mathbf{x}|| = |\lambda| ||\mathbf{x}||\\
            ||A\mathbf{x}|| &\leq ||A|| \, ||\mathbf{x}||
        \end{aligned}
        \right.
        \quad
        \Rightarrow \quad
        ||A\mathbf{x}|| = |\lambda| ||\mathbf{x}|| \leq ||A|| \, ||\mathbf{x}||
    \end{align*}
    This is a generic $\lambda$, so this inequality holds for every eigenvalue of $A$
    therefore it holds for the maximum among the $|\lambda_i|$.
\end{itemize}